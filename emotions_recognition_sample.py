# -*- coding: utf-8 -*-
"""Emotions Recognition Sample.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vjh7kdGdia1Osu9TxFKGFPxFuzF_Dw2K
"""

from google.colab import drive
drive.mount('/content/drive')

!ls

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/MyDrive/facial_expression

!ls

import tarfile

fname = 'fer2013.tar.gz'

if fname.endswith("tar.gz"):
    tar = tarfile.open(fname, "r:gz")
    tar.extractall()
    tar.close()
elif fname.endswith("tar"):
    tar = tarfile.open(fname, "r:")
    tar.extractall()
    tar.close()

import os
import numpy as np
import tensorflow as tf
from matplotlib import pyplot
import pandas as pd
from sklearn.model_selection import train_test_split

df = pd.read_csv('fer2013/fer2013.csv')
df.head()

df.emotion.unique()

label_to_text = {0:'anger', 1:'disgust', 2:'fear', 3:'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}

np.array(df.pixels.loc[0].split(' ')).reshape(48,48)

fig = pyplot.figure(1, (14, 14))
k = 0
for label in sorted(df.emotion.unique()):
    for j in range(3):
        px = df[df.emotion==label].pixels.iloc[k]
        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')
        k += 1
        ax = pyplot.subplot(7, 7, k)
        ax.imshow(px)
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_title(label_to_text[label])
        pyplot.tight_layout()

img_array = df.pixels.apply(lambda x: np.array(x.split(' ')).reshape(48, 48, 1).astype('float32'))

img_array = np.stack(img_array,axis=0)

img_array.shape

pyplot.imshow(img_array[1])

lables = df.emotion.values

X_train, x_test, y_train, y_test = train_test_split(img_array, lables, test_size = .1)

X_train.shape, y_train.shape, x_test.shape, y_test.shape

X_train = X_train/255
X_test = x_test/255

basemodel = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32,(3,3),activation = 'relu', input_shape = (48,48,1)),
    tf.keras.layers.MaxPool2D(2,2),
    tf.keras.layers.BatchNormalization(),

    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu', input_shape = (48,48,1)),
    tf.keras.layers.MaxPool2D(2,2),
    tf.keras.layers.BatchNormalization(),

    tf.keras.layers.Conv2D(128,(3,3),activation = 'relu', input_shape = (48,48,1)),
    tf.keras.layers.MaxPool2D(2,2),
    tf.keras.layers.BatchNormalization(),

    tf.keras.layers.Flatten(),

    tf.keras.layers.Dense(128, activation = 'relu'),

    tf.keras.layers.Dense(7,activation = 'softmax')

])

basemodel.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.0001),
                  loss = 'sparse_categorical_crossentropy',
                  metrics = ['accuracy'])

import os
try:
  os.mkdir('checkpoint')
except:
  pass

file_name = 'best_model.h5'
checkpoint_path= os.path.join('checkpoint',file_name)


call_back = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 monitor='val_accuracy',
                                                 verbose=1,
                                                 save_freq='epoch',
                                                 save_best_only=True,
                                                 save_weights_only=False,
                                                 mode='max')

basemodel.fit(X_train,y_train, epochs =20, validation_split = .1, callbacks = call_back)

def plot_model_history(model_history):
    """
    Plot Accuracy and Loss curves given the model_history
    """
    fig, axs = plt.subplots(1,2,figsize=(15,5))
    # summarize history for accuracy
    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])
    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])
    axs[0].set_title('Model Accuracy')
    axs[0].set_ylabel('Accuracy')
    axs[0].set_xlabel('Epoch')
    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)
    axs[0].legend(['train', 'val'], loc='best')
    # summarize history for loss
    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])
    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])
    axs[1].set_title('Model Loss')
    axs[1].set_ylabel('Loss')
    axs[1].set_xlabel('Epoch')
    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)
    axs[1].legend(['train', 'val'], loc='best')
    fig.savefig('plot.png')
    plt.show()